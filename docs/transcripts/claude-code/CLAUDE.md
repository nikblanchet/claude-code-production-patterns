# CLAUDE.md

**NOTE: This file is gitignored and should NOT be committed to the repository.**

This file provides technical guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Session Initialization

**IMPORTANT**: Before starting any work, always read `CLAUDE_CONTEXT.md` (gitignored) for:
- Additional project context
- User workflow preferences and communication style

This file is gitignored to keep personal preferences separate from the technical documentation below.

## Project Overview

**DocImp** is an impact-driven documentation coverage tool that analyzes Python, TypeScript, and JavaScript codebases to identify undocumented code, prioritizes it by impact score, and uses Claude AI to generate validated documentation.

**Key Principles:**
- **Polyglot Architecture**: Python for analysis engine, TypeScript for CLI, JavaScript for configuration and plugins
- **JavaScript as First-Class Citizen**: Real JSDoc type-checking with TypeScript compiler (`checkJs: true`), not just parsing
- **Clean Dependency Injection**: Constructor injection in both Python and TypeScript for testability
- **Plugin-Based Validation**: JavaScript plugins catch AI-generated documentation errors before acceptance
- **Impact-Based Prioritization**: Complex, high-visibility code gets documented first

## Commands

### Development Setup

```bash
# Install Python dependencies
pip install -r requirements.txt

# Install and build TypeScript CLI
cd cli
npm install
npm run build
npm link

# Verify installation
docimp --version
```

### Running the Application

```bash
# Analyze documentation coverage
docimp analyze ./src

# Audit existing documentation quality (interactive)
docimp audit ./src

# Generate improvement plan
docimp plan ./src

# Interactive documentation improvement (requires ANTHROPIC_API_KEY)
export ANTHROPIC_API_KEY=sk-ant-...
docimp improve ./src
```

### Testing

```bash
# Python tests
cd analyzer
pytest -v
pytest -v --cov=src  # With coverage

# TypeScript tests
cd cli
npm test
npm test -- --watch  # Watch mode

# Integration tests
npm run test:integration

# Linting
cd analyzer && ruff check .
cd cli && npm run lint
```

### Building

```bash
# Build TypeScript CLI
cd cli
npm run build

# Development build with watch
npm run build:watch
```

## Architecture

### Three-Layer Polyglot Design

```
┌─────────────────────────────────────────────────────────────────┐
│                     TypeScript CLI Layer                        │
│  - Commander.js for commands (analyze, audit, plan, improve)    │
│  - ConfigLoader: loads JavaScript config files                  │
│  - PluginManager: executes JavaScript validation plugins        │
│  - PythonBridge: spawns Python subprocess, parses JSON          │
│  - TerminalDisplay: formatted output with chalk/cli-table3      │
└─────────────────────────────────────────────────────────────────┘
                              ↕
                   Subprocess Communication (JSON)
                              ↕
┌─────────────────────────────────────────────────────────────────┐
│                    Python Analysis Engine                        │
│  - Parsers: PythonParser (AST), TypeScriptParser (TS Compiler)  │
│  - ImpactScorer: calculates 0-100 priority scores               │
│  - DocumentationAnalyzer: orchestrates parsing + scoring         │
│  - ClaudeClient: generates documentation suggestions            │
│  - DocstringWriter: inserts docs into source files              │
└─────────────────────────────────────────────────────────────────┘
                              ↕
┌─────────────────────────────────────────────────────────────────┐
│                  JavaScript Config & Plugins                     │
│  - docimp.config.js: user configuration (CommonJS or ESM)       │
│  - plugins/validate-types.js: JSDoc validation with TS compiler │
│  - plugins/jsdoc-style.js: style enforcement                    │
└─────────────────────────────────────────────────────────────────┘
```

### Data Flow

1. **User runs** `docimp analyze ./code`
2. **TypeScript CLI** loads `docimp.config.js` (JavaScript file with custom logic)
3. **PythonBridge** spawns Python subprocess: `python -m analyzer analyze ./code --format json`
4. **Python Analyzer** discovers files and routes to appropriate parser:
   - `.py` → `PythonParser` (built-in AST module)
   - `.ts/.js/.cjs/.mjs` → `TypeScriptParser` (spawns Node with TS compiler, `checkJs: true`)
5. **Parsers extract** `CodeItem` objects with metadata: name, type, complexity, docstring presence, export type, module system
6. **ImpactScorer** calculates 0-100 priority based on cyclomatic complexity (and optionally audit ratings)
7. **Python returns** `AnalysisResult` as JSON to stdout
8. **TypeScript CLI** parses JSON and uses `TerminalDisplay` to format output

### Interactive Improve Flow

1. User selects item to document (from plan generated by `docimp plan`)
2. Python's `PromptBuilder` creates context-rich prompt (code + style guide + tone)
3. `ClaudeClient` requests documentation suggestion
4. **TypeScript `PluginManager` runs validation** (e.g., JSDoc type-checking via TS compiler)
5. Plugin returns `{accept: boolean, reason?: string, autoFix?: string}`
6. User chooses: [A] Accept, [E] Edit, [R] Regenerate (with feedback), [S] Skip, [Q] Quit
7. If accepted: Python's `DocstringWriter` inserts documentation into source file

## Core Data Models

### CodeItem (Python)

```python
@dataclass
class CodeItem:
    """Represents a parsed function, class, or method."""
    name: str                    # Function/class name
    type: str                    # 'function', 'class', 'method'
    filepath: str
    line_number: int
    language: str                # 'python', 'typescript', 'javascript', 'skipped'
    complexity: int              # Cyclomatic complexity
    impact_score: float          # 0-100 priority score
    has_docs: bool               # Binary: has documentation or not
    parameters: List[str]
    return_type: Optional[str]
    docstring: Optional[str]
    export_type: str             # 'named', 'default', 'commonjs', 'internal'
    module_system: str           # 'esm', 'commonjs', 'unknown'
    audit_rating: Optional[int]  # 1-4 rating from audit, or None if skipped/not audited
```

### AnalysisResult (Python)

```python
@dataclass
class AnalysisResult:
    """Results from analyzing a codebase."""
    items: List[CodeItem]
    coverage_percent: float
    total_items: int
    documented_items: int
    by_language: Dict[str, LanguageMetrics]  # Breakdown per language
```

## Dependency Injection Pattern

All major components use constructor injection for testability and modularity:

**Python Example:**
```python
# DocumentationAnalyzer accepts injected parsers and scorer
analyzer = DocumentationAnalyzer(
    parsers={
        'python': PythonParser(),
        'javascript': TypeScriptParser()  # Handles both .ts and .js
    },
    scorer=ImpactScorer()
)
```

**TypeScript Example:**
```typescript
// Commands accept injected dependencies
const analyzeCommand = new AnalyzeCommand(
  pythonBridge: IPythonBridge,
  display: IDisplay
);
```

**Key Principle**: Never use `new` inside production code. Always inject dependencies through constructors. This enables:
- Easy mocking in tests
- Swapping implementations (e.g., mock Python bridge during tests)
- Clear dependency graphs

## JavaScript Handling - Critical Details

DocImp treats JavaScript as **first-class**, not just "TypeScript that parses .js files."

### TypeScript Configuration

**Critical settings in `cli/tsconfig.json`:**
```json
{
  "compilerOptions": {
    "allowJs": true,           // Parse JavaScript files
    "checkJs": true,           // Type-check JSDoc in .js files (CRITICAL)
    "module": "NodeNext",      // Deterministic ESM/CJS interop
    "moduleResolution": "NodeNext"
  }
}
```

**`checkJs: true` enables REAL JSDoc validation**, not cosmetic parsing. The TypeScript compiler validates:
- Parameter names match function signatures
- JSDoc types are correct
- Return types align with implementation

### Module System Detection

The `TypeScriptParser` must detect and record module systems:

**ESM (ES Modules):**
```javascript
export function add(a, b) { return a + b; }
export default class Calculator {}
```

**CommonJS:**
```javascript
module.exports = { add };
exports.subtract = (a, b) => a - b;
```

**Detection logic**: Presence of `export`/`import` keywords → ESM, otherwise CommonJS. File extensions `.mjs` and `.cjs` are explicit indicators.

### JSDoc Write Patterns

The `DocstringWriter` (Python) must correctly insert JSDoc above various JavaScript patterns:

```javascript
// Function declaration
function foo() {}

// Export function
export function foo() {}

// Default export
export default function foo() {}

// Arrow function (JSDoc goes above const)
const foo = () => {};

// Async arrow function
const fetchData = async () => {};

// Class methods
class Service {
  async getData() {}
  static helper() {}
  get value() {}
}

// Object literal methods
module.exports = {
  foo() {},
  bar: function() {}
};

// CommonJS patterns
module.exports.baz = () => {};
exports.qux = function() {};
```

**Requirements:**
- Preserve indentation exactly
- Avoid duplicate comments (idempotent)
- Insert JSDoc (`/** */`) not regular comments (`/* */` or `//`)
- Handle all export styles (named, default, CommonJS)

## Impact Scoring Algorithm

DocImp calculates 0-100 impact scores to prioritize documentation needs.

### Complexity Calculation: Radon vs McCabe

DocImp uses **Radon-style per-function complexity** (not McCabe-style aggregate complexity).

**Key Decision**: When a function contains nested functions, complexity is calculated **separately for each function**. Decision points in nested functions do NOT contribute to the parent function's complexity.

**Example:**
```python
def parent(x):
    if x > 0:  # Parent complexity: base(1) + if(1) = 2
        return True

    def nested(y):
        if y < 0:  # Nested complexity: base(1) + if(1) = 2
            return False
        while y < 100:  # Nested complexity: +1 = 3
            y += 1
        return True

    return False

# Radon-style (current): parent=2, nested=3 (separate)
# McCabe-style (not used): parent=5 (aggregate including nested)
```

**Rationale for Radon-style:**
1. **Documentation separation of concerns**: Each function gets its own docstring. Readers can navigate to nested functions to learn implementation details.
2. **Implementation simplicity**: Separate calculations align with how DocImp already extracts nested functions as independent `CodeItem` objects.
3. **Industry adoption**: Radon is the default for CodeFactor and many CI/CD systems.
4. **Future enhancement planned**: Issue #145 proposes adding McCabe-style aggregate complexity as an **additional metric** (not a replacement). Both metrics together provide complementary information.

**Research Sources**: See issue #66 comments for detailed analysis of Radon and McCabe source code showing their fundamentally different approaches.

### Formula

**Without Audit (MVP):**
```
impact_score = min(100, cyclomatic_complexity * 5)
```

**With Audit (after running `docimp audit`):**
```
impact_score = (complexity_weight × complexity_score) +
               (quality_weight × quality_penalty)

where:
  complexity_score = min(100, cyclomatic_complexity * 5)
  quality_penalty = rating_to_penalty(user_audit_rating)

  default weights: complexity=0.6, quality=0.4
```

### Audit Rating to Penalty

| User Rating | Penalty | Priority |
|-------------|---------|----------|
| No docs | 100 | Highest |
| Terrible (1) | 80 | Very High |
| OK (2) | 40 | Medium |
| Good (3) | 20 | Low |
| Excellent (4) | 0 | Lowest |

### Examples

- Simple function (complexity 1): **score = 5**
- Complex function (complexity 15): **score = 75**
- Complex function with terrible docs (complexity 15, rating 1): **score = 75×0.6 + 80×0.4 = 77**

## Plugin System

Plugins are **user-controlled JavaScript files with NO sandboxing**. They run with full Node.js access.

### Plugin Interface

```typescript
interface IPlugin {
  name: string;
  version: string;
  hooks: {
    beforeAccept?: (docstring: string, item: CodeItem, config: IConfig) => Promise<PluginResult>;
    afterWrite?: (filepath: string, item: CodeItem) => Promise<PluginResult>;
  };
}

interface PluginResult {
  accept: boolean;      // true = allow, false = block
  reason?: string;      // Error message if blocked
  autoFix?: string;     // Suggested correction
}
```

### Built-in Plugins

1. **`plugins/validate-types.js`** - Real JSDoc type-checking
   - Uses TypeScript compiler programmatically
   - Creates in-memory TS program with `checkJs: true`
   - Validates parameter names match function signatures
   - Validates types are correct
   - Returns specific error messages with line numbers

2. **`plugins/jsdoc-style.js`** - Style enforcement
   - Checks preferred tag aliases (e.g., `@returns` vs `@return`)
   - Validates descriptions end with punctuation
   - Requires `@example` for public APIs (configurable)

### Security Model

**Trade-offs:**
- ✅ Full access to Node.js APIs and TypeScript compiler
- ✅ Real validation (not just pattern matching)
- ❌ No security boundary - plugins have full file system access
- ❌ User must trust plugin source code

**Default behavior**: Only load plugins from `./plugins/` or paths in `docimp.config.js`.

## Configuration System

DocImp uses **JavaScript configuration files** (not JSON) to allow custom logic and functions.

### Example: `docimp.config.js`

```javascript
module.exports = {
  // Style guide: 'numpy', 'google', 'sphinx', 'jsdoc'
  styleGuide: 'jsdoc',

  // Tone: 'concise', 'detailed', 'friendly'
  tone: 'concise',

  // JSDoc-specific options
  jsdocStyle: {
    preferredTags: { return: 'returns', arg: 'param' },
    requireDescriptions: true,
    requireExamples: 'public',  // 'all', 'public', 'none'
    enforceTypes: true
  },

  // Impact scoring weights (complexity vs quality)
  impactWeights: {
    complexity: 0.6,  // 60% from cyclomatic complexity
    quality: 0.4      // 40% from audit quality rating
  },

  // Validation plugins (JavaScript files)
  plugins: [
    './plugins/validate-types.js',
    './plugins/jsdoc-style.js'
  ],

  // File exclusions (glob patterns)
  exclude: [
    '**/test_*.py',
    '**/*.test.ts',
    '**/node_modules/**',
    '**/venv/**',
    '**/__pycache__/**'
  ]
};
```

**Supports both CommonJS and ESM:**
- CommonJS: `module.exports = { /* config */ };`
- ESM: `export default { /* config */ };`

## Testing Strategy

### Python Tests (pytest)

```bash
cd analyzer
pytest -v
pytest -v --cov=src  # With coverage
```

**Focus areas:**
- Parser smoke tests (Python, TypeScript, JavaScript)
- Scorer monotonicity (complex > simple scores)
- Coverage calculator correctness
- JavaScript integration tests (analyze JS project)
- Writer tests for JavaScript patterns (7+ test cases)
- Mock Claude client for deterministic tests

### TypeScript Tests (Jest)

```bash
cd cli
npm test
npm test -- --watch  # Watch mode
```

**Focus areas:**
- Config loader (CommonJS and ESM configs)
- Plugin manager (loading, execution, error isolation)
- JSDoc validation (checkJs enforcement)
- ESM/CJS detection tests
- Python bridge mock tests
- Display formatting tests

### CI/CD (GitHub Actions)

**Matrix strategy:**
- Python: 3.13 (can expand later)
- Node: 22 (can expand later)
- **Module system matrix**: CommonJS vs ESM
- Linting: ruff (Python), eslint + eslint-plugin-jsdoc (TypeScript/JavaScript)
- Type checking: mypy (Python), tsc --noEmit (TypeScript)

### Test Organization and Structure

**CRITICAL: Always create permanent test files, never run ad-hoc validation scripts.**

#### Python Test Structure

**Location**: `analyzer/tests/`

**Import Pattern**:
```python
import sys
from pathlib import Path
import pytest

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

# Use relative imports from src/
from src.parsers.python_parser import PythonParser
from src.models.code_item import CodeItem
```

**Path Handling for Test Files**:
```python
@pytest.fixture
def test_file(self):
    """Return path to test Python file."""
    # Get path relative to project root (tests/ -> analyzer/ -> docimp/)
    project_root = Path(__file__).parent.parent.parent
    return str(project_root / 'examples' / 'test_simple.py')
```

**Key Rules**:
- All test files go in `analyzer/tests/test_*.py`
- Use `sys.path.insert(0, str(Path(__file__).parent.parent))` at the top
- Import from `src.*` (not `analyzer.src.*`)
- Use relative imports in source code (`from .base_parser import BaseParser`)
- Test fixtures for file paths must account for pytest running from `analyzer/` directory

#### TypeScript Test Structure

**Location**: `cli/src/__tests__/`

**Import Pattern**:
```typescript
import { PythonBridge } from '../python-bridge/PythonBridge';
import { ConfigLoader } from '../config/ConfigLoader';
```

**Key Rules**:
- All test files go in `cli/src/__tests__/*.test.ts`
- Use relative imports from parent directories
- Mock external dependencies (Python bridge, file system, etc.)
- Use Jest conventions

#### Bash Script Test Structure

**Location**: `test-samples/*.sh`

**Purpose**: Manual testing scripts for features requiring API keys or interactive user input.

**Conventions**:
```bash
#!/bin/bash
set -e  # Exit on error

# Color codes for output
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Change to appropriate directory
cd "$(dirname "$0")/target-directory" || exit 1
```

**Structure Pattern**:
1. **Prerequisites validation** - Check required tools (API keys, jq, git, etc.)
2. **State cleanup** - Remove old state, restore files to clean state
3. **Progressive workflow** - Execute commands in logical sequence
4. **Clear instructions** - Echo step names, provide user guidance
5. **Automatic validation** - Use git diff, file checks, JSON parsing to verify results
6. **Restoration workflow** - Prompt user to restore or preserve test state
7. **Additional testing suggestions** - Document edge cases and variations

**Output Guidelines**:
- Use color-coded status indicators (✓ for success, ✗ for failure)
- Echo command being run before execution (`echo "Running: docimp analyze ."`)
- Provide clear section headers with visual separation
- Show actionable error messages with installation instructions
- Display validation results (git diff, file contents)

**Error Handling**:
- Validate prerequisites before any work (fail fast)
- Provide clear error messages with resolution steps
- Exit with non-zero status on critical failures
- Use `|| true` only for expected failures (like user quitting early)

**Validation**:
- Syntax check: `bash -n script.sh`
- Make executable: `chmod +x script.sh`
- Test with clean state (no API key, missing dependencies)
- Test with successful workflow
- Verify restoration workflow works

**Example Scripts**:
- `test-samples/test-workflows-improve.sh` - Manual testing for improve command
- `test-samples/test-workflows-b.sh` - Automated workflow testing (analyze → audit → plan)

**When to Use**:
- Features requiring external API keys (Claude API)
- Interactive user input that cannot be easily mocked
- Integration tests spanning multiple commands
- Manual validation checklists for releases

**Future Path**:
Bash scripts should document how they can be converted to automated tests:
- Mock external dependencies (ClaudeClient, API calls)
- Programmatically provide user input
- Add to CI/CD pipeline
- See Issue #186 for ClaudeClient mocking example

#### Why This Matters

**Problem**: Running ad-hoc validation scripts (e.g., `python -c "..."`) wastes work and doesn't protect against regressions.

**Solution**: All validation must be captured in permanent test files that:
- Run in CI/CD
- Catch regressions
- Document expected behavior
- Can be maintained and extended

**When to create tests**:
- **Immediately** after implementing new functionality
- **Before** marking a feature as complete
- **Always** - there are no exceptions

## Common Patterns

### Adding a New Parser

1. Create parser in `analyzer/src/parsers/` inheriting from `BaseParser`
2. Implement `parse_file(filepath: str) -> List[CodeItem]`
3. Register in `DocumentationAnalyzer` parsers dict
4. Add tests in `analyzer/tests/test_parsers.py`

### Adding a New Plugin

1. Create JavaScript file in `plugins/`
2. Export object with `name`, `version`, and `hooks`
3. Implement `beforeAccept` or `afterWrite` hook
4. Add to `docimp.config.js` plugins array
5. Add tests in `cli/src/__tests__/plugins.test.ts`

### Adding a New Command

1. Create command in `cli/src/commands/` implementing Commander.js pattern
2. Accept injected dependencies (bridge, display, config)
3. Add Python counterpart in `analyzer/src/main.py` if needed
4. Update `cli/src/index.ts` to register command
5. Add tests for both TypeScript and Python layers

**Commander.js Option Naming Convention**:
- CLI options use kebab-case: `--audit-file`, `--plan-file`, `--quality-threshold`
- Commander.js automatically converts to camelCase in code: `options.auditFile`, `options.planFile`, `options.qualityThreshold`
- This is standard Commander.js behavior - no manual conversion needed

## Known Limitations

- **No sandboxing for plugins**: Plugins run with full Node.js access
- **Sequential improve workflow**: No save/resume sessions (future enhancement)
- **Basic impact scoring**: Uses only complexity in MVP; pattern detection (DI, async, decorators) planned for future
- **Limited style guides**: MVP supports NumPy (Python) and JSDoc (JavaScript/TypeScript); Sphinx, Google styles planned

## File Structure

```
docimp/
├── cli/                              # TypeScript CLI layer
│   ├── src/
│   │   ├── index.ts                 # Entry point
│   │   ├── commands/                # analyze, audit, plan, improve
│   │   ├── config/                  # ConfigLoader, IConfig
│   │   ├── plugins/                 # PluginManager, IPlugin
│   │   ├── display/                 # TerminalDisplay, IDisplay
│   │   ├── python-bridge/           # PythonBridge, IPythonBridge
│   │   └── types/                   # TypeScript definitions
│   ├── parsers/
│   │   └── ts-js-parser-helper.ts   # TS compiler integration
│   ├── tsconfig.json                # allowJs + checkJs enabled
│   └── package.json
├── analyzer/                         # Python analysis engine
│   └── src/
│       ├── main.py                  # Python CLI entry point
│       ├── models/                  # CodeItem, AnalysisResult
│       ├── parsers/                 # BaseParser, PythonParser, TypeScriptParser
│       ├── scoring/                 # ImpactScorer
│       ├── analysis/                # DocumentationAnalyzer, CoverageCalculator
│       ├── claude/                  # ClaudeClient, PromptBuilder
│       └── writer/                  # DocstringWriter
├── plugins/                          # JavaScript plugins
│   ├── validate-types.js            # Real JSDoc type-checking
│   ├── jsdoc-style.js               # Style enforcement
│   └── README.md                    # Plugin API + Security
├── examples/                         # Test files
│   ├── test_simple.py
│   ├── test_simple.ts
│   ├── test_javascript_patterns.js  # ESM with JSDoc types
│   └── test_commonjs.cjs            # CommonJS patterns
├── requirements.txt                 # Python dependencies
├── docimp.config.js                 # User configuration
└── README.md
```

## Development Workflow

This project is being built using **Claude Code** (claude.ai/code) with:
- **Session atomicity**: Each instance completes a specific deliverable
- **Contract-based development**: Clear inputs, outputs, rollback plans
- **Progressive context**: Build complexity incrementally
- **Test-first validation**: Validate at each step

See `PLAN.md` for the complete 31-step execution plan with 16 Claude Code instances.

### Tracking Progress in PLAN.md

**CRITICAL: Update PLAN.md checkboxes as you complete substeps, not at the end.**

**PLAN.md is gitignored** - it's a working document for tracking progress, not part of the public repository.

**Process**:
1. When you complete a substep (e.g., "Create BaseParser abstract class"), immediately mark it as `[X]` in PLAN.md
2. Mark checkboxes as you go, not in batch at the end of a step
3. This preserves progress if context is lost mid-step
4. Use simple `[X]` notation - do NOT add "COMPLETE:" or other prefixes

**Example workflow**:
```
# Start of step - all unchecked
- [ ] Create BaseParser abstract class
- [ ] Implement PythonParser using AST
- [ ] Create test file

# After creating BaseParser
- [X] Create BaseParser abstract class  ← Mark immediately
- [ ] Implement PythonParser using AST
- [ ] Create test file

# After implementing PythonParser
- [X] Create BaseParser abstract class
- [X] Implement PythonParser using AST  ← Mark immediately
- [ ] Create test file

# And so on...
```

**Why this matters**: If a session ends mid-step, the next Claude Code instance can see exactly what was completed and what remains.
